{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, RFECV, SelectFromModel\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_path(file_id):\n",
    "    \"\"\"Generate a shareable link from Google Drive file id.\"\"\"\n",
    "    return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "files_id = {\n",
    "    'housing_data':\"1kX_jcLeBpBGvTo8FXDeU2MK-aw1a0voU\", #iteration7 data\n",
    "    'test_housing_data':\"1CMsAWhWKWBjI6DDEHtcYmRVZRazfE9bo\", #test data for housing\n",
    "    'ids_com':\"10gwiL49calkj-xbx-3rQEK4H2zoJcU11\" #ID for the commiting of the project\n",
    "\n",
    "}\n",
    "\n",
    "housing_data = pd.read_csv(gd_path(files_id['housing_data']), sep=\",\")\n",
    "test_housing_data = pd.read_csv(gd_path(files_id['test_housing_data']), sep=\",\")\n",
    "ids_com = pd.read_csv(gd_path(files_id['ids_com']), sep=\",\")\n",
    "df = housing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part was done by hands. Many Bothans died to bring us this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X and y creation\n",
    "y = df.pop(\"SalePrice\")\n",
    "\n",
    "# Feature Engineering\n",
    "X = df\n",
    "\n",
    "# data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the pipeline\n",
    "X_cat = X.select_dtypes(exclude=\"number\").copy()\n",
    "X_num = X.select_dtypes(include=\"number\").copy()\n",
    "\n",
    "#  numerical pipeline\n",
    "numeric_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    MinMaxScaler(),\n",
    "    VarianceThreshold(threshold=0.02)) # maybe remove it\n",
    "    \n",
    "\n",
    "\n",
    "# categorical pipeline\n",
    "# defining ordinal & onehot columns\n",
    "\n",
    "ordinal_cols = X_cat.columns.get_indexer(['LandContour', 'LandSlope',\n",
    "                     'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "                     'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                     'HeatingQC', 'KitchenQual', 'Functional',\n",
    "                     'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                     'PoolQC']) \n",
    "\n",
    "onehot_cols = X_cat.columns.get_indexer(['MSZoning', 'Condition1', 'Heating', 'Street', 'CentralAir', \n",
    "                                         'Foundation', 'Alley', 'LotShape', 'Utilities', 'LotConfig', \n",
    "                                         'Neighborhood', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "                                         'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', \n",
    "                                         'Electrical', 'GarageType', 'PavedDrive', 'Fence', 'MiscFeature',\n",
    "                                         'SaleType', 'SaleCondition'])\n",
    "\n",
    "\n",
    "\n",
    "# defining the categorical encoder\n",
    "# we manually establish the order of the categories for our ordinal feature (Cabin), including \"N_A\"\n",
    "LandContour = ['Lvl', 'Bnk', 'HLS', 'Low']\n",
    "LandSlope = ['Gtl', 'Mod', 'Sev']\n",
    "ExterQual = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "ExterCond = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "BsmtQual = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'N_A']\n",
    "BsmtCond = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'N_A']\n",
    "BsmtExposure = ['Gd', 'Av', 'Mn', 'No', 'N_A']\n",
    "BsmtFinType1 = ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'N_A']\n",
    "BsmtFinType2 = ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'N_A']\n",
    "HeatingQC = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "KitchenQual = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n",
    "Functional = ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal']\n",
    "FireplaceQu = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'N_A']\n",
    "GarageFinish = ['Fin', 'RFn', 'Unf', 'N_A']\n",
    "GarageQual = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'N_A']\n",
    "GarageCond = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'N_A']\n",
    "PoolQC = ['Ex', 'Gd', 'TA', 'Fa', 'N_A']\n",
    "\n",
    "\n",
    "categorical_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_ordinal\", OrdinalEncoder(categories=[LandContour,LandSlope,\n",
    "                                                    ExterQual, ExterCond, BsmtQual, BsmtCond,\n",
    "                                                    BsmtExposure, BsmtFinType1, BsmtFinType2,\n",
    "                                                    HeatingQC, KitchenQual, Functional,\n",
    "                                                    FireplaceQu, GarageFinish, GarageQual, GarageCond,\n",
    "                                                    PoolQC]), ordinal_cols),\n",
    "\n",
    "        (\"cat_onehot\", OneHotEncoder(handle_unknown=\"ignore\"), onehot_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "categoric_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"N_A\"),\n",
    "    categorical_encoder \n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_pipe\", numeric_pipe, X_num.columns),\n",
    "        (\"cat_pipe\", categoric_pipe, X_cat.columns),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.00000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.00000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.00000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.185616</td>\n",
       "      <td>0.062329</td>\n",
       "      <td>1.60411</td>\n",
       "      <td>1.916438</td>\n",
       "      <td>1.510959</td>\n",
       "      <td>2.065068</td>\n",
       "      <td>2.369863</td>\n",
       "      <td>2.454110</td>\n",
       "      <td>4.752740</td>\n",
       "      <td>0.854795</td>\n",
       "      <td>1.488356</td>\n",
       "      <td>0.158219</td>\n",
       "      <td>3.174658</td>\n",
       "      <td>1.284247</td>\n",
       "      <td>2.189726</td>\n",
       "      <td>2.191096</td>\n",
       "      <td>3.986986</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.044521</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.788356</td>\n",
       "      <td>0.149315</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.978082</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.995890</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.934932</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.434247</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.937671</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.331507</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.633562</td>\n",
       "      <td>0.999315</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.180137</td>\n",
       "      <td>0.064384</td>\n",
       "      <td>0.032192</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.720548</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.039726</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.102740</td>\n",
       "      <td>0.034932</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.054110</td>\n",
       "      <td>0.025342</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.154110</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.05274</td>\n",
       "      <td>0.077397</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.050685</td>\n",
       "      <td>0.040411</td>\n",
       "      <td>0.058904</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.078082</td>\n",
       "      <td>0.105479</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.497260</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.304795</td>\n",
       "      <td>0.025342</td>\n",
       "      <td>0.044521</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.781507</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.195890</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.982192</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.041781</td>\n",
       "      <td>0.152055</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.073973</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.352740</td>\n",
       "      <td>0.141096</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.141781</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.146575</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.097260</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.134932</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.304795</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.591781</td>\n",
       "      <td>0.087671</td>\n",
       "      <td>0.064384</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.913699</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.595890</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.265068</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.040411</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>0.107534</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.807534</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.963014</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.867808</td>\n",
       "      <td>0.069178</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.820548</td>\n",
       "      <td>0.085616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.606509</td>\n",
       "      <td>0.276232</td>\n",
       "      <td>0.57428</td>\n",
       "      <td>0.351054</td>\n",
       "      <td>0.876478</td>\n",
       "      <td>0.552159</td>\n",
       "      <td>1.067391</td>\n",
       "      <td>2.107776</td>\n",
       "      <td>0.892332</td>\n",
       "      <td>0.959501</td>\n",
       "      <td>0.663760</td>\n",
       "      <td>0.667698</td>\n",
       "      <td>1.810877</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.722898</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.204059</td>\n",
       "      <td>0.082505</td>\n",
       "      <td>0.206319</td>\n",
       "      <td>0.104145</td>\n",
       "      <td>0.408614</td>\n",
       "      <td>0.356521</td>\n",
       "      <td>0.178375</td>\n",
       "      <td>0.228992</td>\n",
       "      <td>0.343951</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.132299</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.146465</td>\n",
       "      <td>0.110386</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>0.246731</td>\n",
       "      <td>0.300103</td>\n",
       "      <td>0.495827</td>\n",
       "      <td>0.496928</td>\n",
       "      <td>0.127198</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.241835</td>\n",
       "      <td>0.165264</td>\n",
       "      <td>0.470916</td>\n",
       "      <td>0.165264</td>\n",
       "      <td>0.082505</td>\n",
       "      <td>0.481996</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.384433</td>\n",
       "      <td>0.245519</td>\n",
       "      <td>0.176570</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.448884</td>\n",
       "      <td>0.107313</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.104145</td>\n",
       "      <td>0.195382</td>\n",
       "      <td>0.137198</td>\n",
       "      <td>0.303723</td>\n",
       "      <td>0.183669</td>\n",
       "      <td>0.252677</td>\n",
       "      <td>0.226311</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>0.107313</td>\n",
       "      <td>0.180160</td>\n",
       "      <td>0.361177</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>0.21802</td>\n",
       "      <td>0.165264</td>\n",
       "      <td>0.22359</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.219429</td>\n",
       "      <td>0.196989</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.159271</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.100873</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.370750</td>\n",
       "      <td>0.144209</td>\n",
       "      <td>0.185395</td>\n",
       "      <td>0.169128</td>\n",
       "      <td>0.268393</td>\n",
       "      <td>0.307275</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>0.500164</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.460478</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>0.206319</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.413365</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.397021</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.132299</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.116277</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.200157</td>\n",
       "      <td>0.359197</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.357864</td>\n",
       "      <td>0.261816</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.477986</td>\n",
       "      <td>0.348240</td>\n",
       "      <td>0.132299</td>\n",
       "      <td>0.116277</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.198580</td>\n",
       "      <td>0.348945</td>\n",
       "      <td>0.082505</td>\n",
       "      <td>0.353803</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.296413</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.132299</td>\n",
       "      <td>0.475598</td>\n",
       "      <td>0.341767</td>\n",
       "      <td>0.159271</td>\n",
       "      <td>0.100873</td>\n",
       "      <td>0.460478</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.491673</td>\n",
       "      <td>0.282913</td>\n",
       "      <td>0.245519</td>\n",
       "      <td>0.134772</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.280905</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.490887</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.238075</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>0.441521</td>\n",
       "      <td>0.228992</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.141914</td>\n",
       "      <td>0.274751</td>\n",
       "      <td>0.196989</td>\n",
       "      <td>0.188793</td>\n",
       "      <td>0.309897</td>\n",
       "      <td>0.086502</td>\n",
       "      <td>0.394372</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.188793</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.180160</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.169128</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.276824</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.338815</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.090317</td>\n",
       "      <td>0.116277</td>\n",
       "      <td>0.383862</td>\n",
       "      <td>0.279893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1           2            3            4    \\\n",
       "count  1460.000000  1460.000000  1460.00000  1460.000000  1460.000000   \n",
       "mean      0.185616     0.062329     1.60411     1.916438     1.510959   \n",
       "std       0.606509     0.276232     0.57428     0.351054     0.876478   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.00000     2.000000     1.000000   \n",
       "50%       0.000000     0.000000     2.00000     2.000000     1.000000   \n",
       "75%       0.000000     0.000000     2.00000     2.000000     2.000000   \n",
       "max       3.000000     2.000000     3.00000     4.000000     5.000000   \n",
       "\n",
       "               5            6            7            8            9    \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      2.065068     2.369863     2.454110     4.752740     0.854795   \n",
       "std       0.552159     1.067391     2.107776     0.892332     0.959501   \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     2.000000     0.000000     5.000000     0.000000   \n",
       "50%       2.000000     3.000000     2.000000     5.000000     0.000000   \n",
       "75%       2.000000     3.000000     5.000000     5.000000     2.000000   \n",
       "max       5.000000     4.000000     6.000000     6.000000     4.000000   \n",
       "\n",
       "               10           11           12           13           14   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      1.488356     0.158219     3.174658     1.284247     2.189726   \n",
       "std       0.663760     0.667698     1.810877     0.892831     0.722898   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     1.000000     1.000000     2.000000   \n",
       "50%       2.000000     0.000000     3.000000     1.000000     2.000000   \n",
       "75%       2.000000     0.000000     5.000000     2.000000     2.000000   \n",
       "max       3.000000     6.000000     5.000000     3.000000     5.000000   \n",
       "\n",
       "               15           16           17           18           19   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      2.191096     3.986986     0.006849     0.044521     0.010959   \n",
       "std       0.719685     0.204059     0.082505     0.206319     0.104145   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     4.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.000000     4.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000     4.000000     0.000000     0.000000     0.000000   \n",
       "max       5.000000     4.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               20           21           22           23           24   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.788356     0.149315     0.032877     0.055479     0.863014   \n",
       "std       0.408614     0.356521     0.178375     0.228992     0.343951   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               25           26           27           28           29   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.005479     0.013014     0.007534     0.017808     0.001370   \n",
       "std       0.073846     0.113372     0.086502     0.132299     0.036999   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               30           31           32           33           34   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.003425     0.000685     0.978082     0.012329     0.004795   \n",
       "std       0.058440     0.026171     0.146465     0.110386     0.069100   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               35           36           37           38           39   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.001370     0.002740     0.004110     0.995890     0.065068   \n",
       "std       0.036999     0.052289     0.063996     0.063996     0.246731   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               40           41           42           43           44   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.934932     0.100000     0.434247     0.443151     0.016438   \n",
       "std       0.246731     0.300103     0.495827     0.496928     0.127198   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               45           46           47           48           49   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.004110     0.002055     0.034247     0.937671     0.028082   \n",
       "std       0.063996     0.045299     0.181924     0.241835     0.165264   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               50           51           52           53           54   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.331507     0.028082     0.006849     0.633562     0.999315   \n",
       "std       0.470916     0.165264     0.082505     0.481996     0.026171   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               55           56           57           58           59   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.180137     0.064384     0.032192     0.002740   \n",
       "std       0.026171     0.384433     0.245519     0.176570     0.052289   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               60           61           62           63           64   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.720548     0.011644     0.001370     0.010959     0.039726   \n",
       "std       0.448884     0.107313     0.036999     0.104145     0.195382   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               65           66           67           68           69   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.019178     0.102740     0.034932     0.068493     0.054110   \n",
       "std       0.137198     0.303723     0.183669     0.252677     0.226311   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               70           71           72           73           74   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.025342     0.011644     0.033562     0.154110     0.006164   \n",
       "std       0.157217     0.107313     0.180160     0.361177     0.078298   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              75           76          77           78           79   \\\n",
       "count  1460.00000  1460.000000  1460.00000  1460.000000  1460.000000   \n",
       "mean      0.05000     0.028082     0.05274     0.077397     0.017123   \n",
       "std       0.21802     0.165264     0.22359     0.267312     0.129775   \n",
       "min       0.00000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.00000     0.000000     0.00000     0.000000     0.000000   \n",
       "50%       0.00000     0.000000     0.00000     0.000000     0.000000   \n",
       "75%       0.00000     0.000000     0.00000     0.000000     0.000000   \n",
       "max       1.00000     1.000000     1.00000     1.000000     1.000000   \n",
       "\n",
       "               80           81           82           83           84   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.050685     0.040411     0.058904     0.017123     0.026027   \n",
       "std       0.219429     0.196989     0.235526     0.129775     0.159271   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               85           86           87           88           89   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.007534     0.001370     0.004110     0.989726     0.000685   \n",
       "std       0.086502     0.036999     0.063996     0.100873     0.026171   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               90           91           92           93           94   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.001370     0.000685     0.000685     0.001370     0.835616   \n",
       "std       0.036999     0.026171     0.026171     0.036999     0.370750   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               95           96           97           98           99   \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.021233     0.035616     0.029452     0.078082     0.105479   \n",
       "std       0.144209     0.185395     0.169128     0.268393     0.307275   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               100          101          102          103          104  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.009589     0.497260     0.005479     0.007534     0.304795   \n",
       "std       0.097486     0.500164     0.073846     0.086502     0.460478   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               105          106          107          108          109  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.025342     0.044521     0.008904     0.781507     0.007534   \n",
       "std       0.157217     0.206319     0.093973     0.413365     0.086502   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               110          111          112          113          114  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.195890     0.004795     0.001370     0.000685     0.982192   \n",
       "std       0.397021     0.069100     0.036999     0.026171     0.132299   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               115          116          117          118          119  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.000685     0.000685     0.007534     0.003425   \n",
       "std       0.026171     0.026171     0.026171     0.086502     0.058440   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               120          121          122          123          124  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.004110     0.013699     0.000685     0.001370     0.034247   \n",
       "std       0.063996     0.116277     0.026171     0.036999     0.181924   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               125          126          127          128          129  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.041781     0.152055     0.000685     0.150685   \n",
       "std       0.026171     0.200157     0.359197     0.026171     0.357864   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               130          131          132          133          134  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.073973     0.001370     0.017123     0.352740     0.141096   \n",
       "std       0.261816     0.036999     0.129775     0.477986     0.348240   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               135          136          137          138          139  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.017808     0.013699     0.002055     0.004795     0.017123   \n",
       "std       0.132299     0.116277     0.045299     0.069100     0.129775   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               140          141          142          143          144  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.041096     0.141781     0.006849     0.146575   \n",
       "std       0.026171     0.198580     0.348945     0.082505     0.353803   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               145          146          147          148          149  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.097260     0.003425     0.017808     0.345205   \n",
       "std       0.026171     0.296413     0.058440     0.132299     0.475598   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               150          151          152          153          154  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.134932     0.026027     0.010274     0.304795     0.005479   \n",
       "std       0.341767     0.159271     0.100873     0.460478     0.073846   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               155          156          157          158          159  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.591781     0.087671     0.064384     0.018493     0.002055   \n",
       "std       0.491673     0.282913     0.245519     0.134772     0.045299   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               160          161          162          163          164  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.000685     0.000685     0.913699     0.004110     0.595890   \n",
       "std       0.026171     0.026171     0.280905     0.063996     0.490887   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               165          166          167          168          169  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.013014     0.060274     0.006164     0.265068     0.055479   \n",
       "std       0.113372     0.238075     0.078298     0.441521     0.228992   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               170          171          172          173          174  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.061644     0.020548     0.917808     0.040411     0.036986   \n",
       "std       0.240590     0.141914     0.274751     0.196989     0.188793   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               175          176          177          178          179  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.107534     0.007534     0.807534     0.001370     0.963014   \n",
       "std       0.309897     0.086502     0.394372     0.036999     0.188793   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               180          181          182          183          184  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.001370     0.033562     0.000685     0.029452     0.002740   \n",
       "std       0.036999     0.180160     0.026171     0.169128     0.052289   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               185          186          187          188          189  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.001370     0.006164     0.003425     0.003425     0.083562   \n",
       "std       0.036999     0.078298     0.058440     0.058440     0.276824   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               190          191          192          193          194  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean      0.002055     0.867808     0.069178     0.002740     0.008219   \n",
       "std       0.045299     0.338815     0.253844     0.052289     0.090317   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               195          196          197  \n",
       "count  1460.000000  1460.000000  1460.000000  \n",
       "mean      0.013699     0.820548     0.085616  \n",
       "std       0.116277     0.383862     0.279893  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     1.000000     0.000000  \n",
       "50%       0.000000     1.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(categoric_pipe.fit_transform(X_cat).toarray()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Smirnov/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'columntransformer__num_pipe__simpleimputer__strategy': 'mean', 'decisiontreeclassifier__max_depth': 10, 'decisiontreeclassifier__min_samples_leaf': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dtree': 0.017989068632845457}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline = make_pipeline(preprocessor,\n",
    "                              DecisionTreeClassifier())\n",
    "\n",
    "param_grid = {\n",
    "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\"],\n",
    "    \"decisiontreeclassifier__max_depth\": [10],\n",
    "    \"decisiontreeclassifier__min_samples_leaf\": [11]\n",
    "}\n",
    "\n",
    "\n",
    "search = GridSearchCV(full_pipeline,\n",
    "                      param_grid,\n",
    "                      cv=5,\n",
    "                      verbose=1)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "scores = {\"dtree\" : search.best_score_}\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisiontree - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.152\n",
      "Testing Accuracy: 0.017 \n",
      "\n",
      "R-squared: 0.454\n",
      "MAPE: 0.191\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the training and testing datasets\n",
    "y_train_pred = search.predict(X_train)\n",
    "y_test_pred = search.predict(X_test)\n",
    "\n",
    "# Create confusion matrices\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Calculate accuracy for training and testing datasets\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", round(accuracy_train,3))\n",
    "print(\"Testing Accuracy:\", round(accuracy_test,3),\"\\n\")\n",
    "\n",
    "\n",
    "dtree_r2 = r2_score(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"R-squared:\", round(dtree_r2,3))\n",
    "\n",
    "dtree_r2 = mean_absolute_percentage_error(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"MAPE:\", round(dtree_r2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Smirnov/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'columntransformer__num_pipe__simpleimputer__strategy': 'mean', 'kneighborsclassifier__n_neighbors': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn': 0.004273504273504274}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling Pipe - 2\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "full_pipeline = make_pipeline(preprocessor,\n",
    "                              KNeighborsClassifier())\n",
    "\n",
    "param_grid = {\n",
    "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\"],\n",
    "    \"kneighborsclassifier__n_neighbors\": [10]\n",
    "}\n",
    "\n",
    "search2 = GridSearchCV(full_pipeline,\n",
    "                      param_grid,\n",
    "                      cv=10,\n",
    "                      verbose=1)\n",
    "\n",
    "search2.fit(X_train, y_train)\n",
    "\n",
    "scores2 = {\"knn\" : search2.best_score_}\n",
    "print(\"Best parameters: \", search2.best_params_)\n",
    "\n",
    "scores2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.11\n",
      "Testing Accuracy: 0.007 \n",
      "\n",
      "R-squared: 0.108\n",
      "MAPE: 0.236\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the training and testing datasets\n",
    "y_train_pred = search2.predict(X_train)\n",
    "y_test_pred = search2.predict(X_test)\n",
    "\n",
    "# Create confusion matrices\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Calculate accuracy for training and testing datasets\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", round(accuracy_train,3))\n",
    "print(\"Testing Accuracy:\", round(accuracy_test,3),\"\\n\")\n",
    "\n",
    "\n",
    "dtree_r2 = r2_score(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"R-squared:\", round(dtree_r2,3))\n",
    "\n",
    "dtree_r2 = mean_absolute_percentage_error(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"MAPE:\", round(dtree_r2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Smirnov/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'columntransformer__num_pipe__simpleimputer__strategy': 'median', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 4, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__n_estimators': 500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf': 0.016272330435420566}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline = make_pipeline(preprocessor,\n",
    "                              RandomForestClassifier())\n",
    "\n",
    "param_grid = {\n",
    "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"median\"],\n",
    "    \"randomforestclassifier__n_estimators\": [500],\n",
    "    \"randomforestclassifier__max_features\": ['sqrt'],\n",
    "    'randomforestclassifier__max_depth' : [4],\n",
    "    'randomforestclassifier__criterion' :['entropy']\n",
    "}\n",
    "\n",
    "\n",
    "'''param_grid = {\n",
    "    \"columntransformer__num_pipe__simpleimputer__strategy\": [\"median\"],\n",
    "    \"randomforestclassifier__n_estimators\": [150],\n",
    "    \"randomforestclassifier__max_depth\": [8],\n",
    "    \"randomforestclassifier__max_features\": [\"sqrt\"],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "'''\n",
    "# need to be rearange \n",
    "search3 = GridSearchCV(full_pipeline,\n",
    "                      param_grid,\n",
    "                      cv=5,\n",
    "                      verbose=1)\n",
    "\n",
    "search3.fit(X_train, y_train)\n",
    "\n",
    "scores3 = {\"rf\" : search3.best_score_}\n",
    "print(\"Best parameters: \", search3.best_params_)\n",
    "scores3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.486\n",
      "Testing Accuracy: 0.017 \n",
      "\n",
      "R-squared: 0.595\n",
      "MAPE: 0.159\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for the training and testing datasets\n",
    "y_train_pred = search3.predict(X_train)\n",
    "y_test_pred = search3.predict(X_test)\n",
    "\n",
    "# Create confusion matrices\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Calculate accuracy for training and testing datasets\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", round(accuracy_train,3))\n",
    "print(\"Testing Accuracy:\", round(accuracy_test,3),\"\\n\")\n",
    "\n",
    "\n",
    "dtree_r2 = r2_score(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"R-squared:\", round(dtree_r2,3))\n",
    "\n",
    "dtree_r2 = mean_absolute_percentage_error(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"MAPE:\", round(dtree_r2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.159\n",
      "R-squared: 0.836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "sgd_pipeline = make_pipeline(preprocessor,\n",
    "                            SGDRegressor())\n",
    "\n",
    "sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "sgd_predictions = sgd_pipeline.predict(X_test)\n",
    "\n",
    "SGD_mape = mean_absolute_percentage_error(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"MAPE:\", round(SGD_mape,3))\n",
    "\n",
    "SGR_r2 = r2_score(y_true = y_test,\n",
    "                    y_pred = sgd_predictions)\n",
    "\n",
    "print(\"R-squared:\", round(SGR_r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.159\n",
      "R-squared: 0.866\n"
     ]
    }
   ],
   "source": [
    "# Scale the data! \n",
    "\n",
    "lr_pipeline = make_pipeline(preprocessor,\n",
    "                            LinearRegression())\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lr_predictions = lr_pipeline.predict(X_test)\n",
    "\n",
    "lr_mape = mean_absolute_percentage_error(y_true = y_test,\n",
    "                    y_pred = y_test_pred)\n",
    "\n",
    "print(\"MAPE:\", round(lr_mape,3))\n",
    "\n",
    "lr_r2 = r2_score(y_true = y_test,\n",
    "                    y_pred = lr_predictions)\n",
    "\n",
    "print(\"R-squared:\", round(lr_r2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>knn</th>\n",
       "      <th>RF</th>\n",
       "      <th>SGDR</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.454</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          decision_tree    knn     RF  SGDR     LR\n",
       "baseline          0.454  0.108  0.595  0.84  0.866"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_tree = search.predict(X_test)\n",
    "y_test_pred_knn = search2.predict(X_test)\n",
    "y_test_pred_rf = search3.predict(X_test)\n",
    "y_test_pred_SGDR = sgd_pipeline.predict(X_test)\n",
    "y_test_pred_lr = lr_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "baseline_tree_r2 = r2_score(y_test, y_test_pred_tree)\n",
    "baseline_knn_r2 = r2_score(y_test, y_test_pred_knn)\n",
    "baseline_rf = r2_score(y_test, y_test_pred_rf)\n",
    "baseline_SGDR = r2_score(y_test, y_test_pred_SGDR)\n",
    "baseline_lr = r2_score(y_test, y_test_pred_lr)\n",
    "\n",
    "\n",
    "performances = pd.DataFrame({'decision_tree': round(baseline_tree_r2,3),\n",
    "                             'knn': round(baseline_knn_r2,3), \n",
    "                             'RF': round(baseline_rf,3),\n",
    "                             'SGDR': round(baseline_SGDR, 2),\n",
    "                            'LR': round(baseline_lr,3)},\n",
    "                            index=['baseline'])\n",
    "\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Range</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>60.0</td>\n",
       "      <td>421.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>292.0</td>\n",
       "      <td>538.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>110.0</td>\n",
       "      <td>619.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>138.0</td>\n",
       "      <td>924.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>508.0</td>\n",
       "      <td>948.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>170.0</td>\n",
       "      <td>1803.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>738.0</td>\n",
       "      <td>2015.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>528.0</td>\n",
       "      <td>2310.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>480.0</td>\n",
       "      <td>3032.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>552.0</td>\n",
       "      <td>3608.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>547.0</td>\n",
       "      <td>4313.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>857.0</td>\n",
       "      <td>16359.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>1474.0</td>\n",
       "      <td>27230.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1170.0</td>\n",
       "      <td>31837.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>1418.0</td>\n",
       "      <td>45114.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>4358.0</td>\n",
       "      <td>156976.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>179135.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>2065.0</td>\n",
       "      <td>191081.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>2336.0</td>\n",
       "      <td>196452.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>6110.0</td>\n",
       "      <td>200852.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>5644.0</td>\n",
       "      <td>216907.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>5308.0</td>\n",
       "      <td>288487.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>15500.0</td>\n",
       "      <td>300135.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>213945.0</td>\n",
       "      <td>88581995.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Range     Variance\n",
       "BsmtHalfBath        2.0         0.05\n",
       "KitchenAbvGr        1.0         0.05\n",
       "HalfBath            2.0         0.25\n",
       "BsmtFullBath        3.0         0.27\n",
       "FullBath            3.0         0.30\n",
       "Fireplaces          3.0         0.41\n",
       "GarageCars          4.0         0.56\n",
       "BedroomAbvGr        8.0         0.69\n",
       "OverallCond         8.0         1.28\n",
       "YrSold              4.0         1.78\n",
       "OverallQual         9.0         1.97\n",
       "TotRmsAbvGrd       12.0         2.71\n",
       "MoSold             11.0         7.23\n",
       "YearRemodAdd       60.0       421.84\n",
       "LotFrontage       292.0       538.47\n",
       "GarageYrBlt       110.0       619.15\n",
       "YearBuilt         138.0       924.01\n",
       "3SsnPorch         508.0       948.84\n",
       "MSSubClass        170.0      1803.09\n",
       "PoolArea          738.0      2015.74\n",
       "LowQualFinSF      528.0      2310.70\n",
       "ScreenPorch       480.0      3032.50\n",
       "EnclosedPorch     552.0      3608.19\n",
       "OpenPorchSF       547.0      4313.24\n",
       "WoodDeckSF        857.0     16359.08\n",
       "BsmtFinSF2       1474.0     27230.94\n",
       "MasVnrArea       1170.0     31837.19\n",
       "GarageArea       1418.0     45114.46\n",
       "1stFlrSF         4358.0    156976.48\n",
       "Id               1459.0    179135.62\n",
       "2ndFlrSF         2065.0    191081.81\n",
       "BsmtUnfSF        2336.0    196452.95\n",
       "TotalBsmtSF      6110.0    200852.56\n",
       "BsmtFinSF1       5644.0    216907.47\n",
       "GrLivArea        5308.0    288487.79\n",
       "MiscVal         15500.0    300135.04\n",
       "LotArea        213945.0  88581995.46"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num = X_train.select_dtypes(include=\"number\").copy()\n",
    "\n",
    "\n",
    "range_var_df = (pd.DataFrame({\n",
    "                'Range': X_train_num.max() - X_train_num.min(),\n",
    "                'Variance': round(X_train_num.var(),2)})\n",
    "                \n",
    "                .sort_values(by='Variance'))\n",
    "\n",
    "range_var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop: KitchenAbvGr, BsmtHalfBath, HalfBath, BsmtFullBath, FullBath, Fireplaces, GarageCars, BedroomAbvGr with Variance under 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Range</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Range  Variance\n",
       "MiscVal          1.0  0.001249\n",
       "LotArea          1.0  0.001935\n",
       "3SsnPorch        1.0  0.003677\n",
       "PoolArea         1.0  0.003701\n",
       "TotalBsmtSF      1.0  0.005380\n",
       "LotFrontage      1.0  0.006315\n",
       "BsmtFinSF1       1.0  0.006809\n",
       "1stFlrSF         1.0  0.008265\n",
       "LowQualFinSF     1.0  0.008288\n",
       "GrLivArea        1.0  0.010239\n",
       "BedroomAbvGr     1.0  0.010801\n",
       "EnclosedPorch    1.0  0.011842\n",
       "BsmtFinSF2       1.0  0.012533\n",
       "BsmtHalfBath     1.0  0.012622\n",
       "ScreenPorch      1.0  0.013162\n",
       "OpenPorchSF      1.0  0.014415\n",
       "TotRmsAbvGrd     1.0  0.018829\n",
       "OverallCond      1.0  0.019947\n",
       "WoodDeckSF       1.0  0.022274\n",
       "GarageArea       1.0  0.022437\n",
       "MasVnrArea       1.0  0.023257\n",
       "OverallQual      1.0  0.024277\n",
       "BsmtFullBath     1.0  0.030422\n",
       "FullBath         1.0  0.033741\n",
       "GarageCars       1.0  0.034779\n",
       "BsmtUnfSF        1.0  0.036001\n",
       "2ndFlrSF         1.0  0.044810\n",
       "Fireplaces       1.0  0.045039\n",
       "KitchenAbvGr     1.0  0.047232\n",
       "YearBuilt        1.0  0.048520\n",
       "GarageYrBlt      1.0  0.051169\n",
       "MoSold           1.0  0.059727\n",
       "MSSubClass       1.0  0.062391\n",
       "HalfBath         1.0  0.063140\n",
       "Id               1.0  0.084153\n",
       "YrSold           1.0  0.111059\n",
       "YearRemodAdd     1.0  0.117177"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler.\n",
    "my_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit the scaler to X_train and fit_transform the values.\n",
    "X_scaled = my_scaler.fit_transform(X_train_num)\n",
    "\n",
    "(\n",
    "  pd.DataFrame({\n",
    "  'Range': X_scaled.max() - X_scaled.min(),\n",
    "  'Variance': X_scaled.var()})\n",
    "  .sort_values(by='Variance')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before: (1168, 37)\n",
      "shape after: (1168, 19)\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.02)\n",
    "X_var = selector.fit_transform(X_scaled)\n",
    "\n",
    "print(\"shape before:\", X_scaled.shape)\n",
    "print(\"shape after:\", X_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test.select_dtypes(include=\"number\").copy()\n",
    "\n",
    "# Scale the test set, transform for train \n",
    "X_test_scaled = my_scaler.transform(X_test_num) \n",
    "\n",
    "# Apply the variance threshold to the scaled test set\n",
    "X_test_var = selector.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 19 features, but ColumnTransformer is expecting 80 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_test_pred_tree \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39mpredict(X_test_var)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_test_pred_knn \u001b[39m=\u001b[39m search2\u001b[39m.\u001b[39mpredict(X_test_var)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_test_pred_rf \u001b[39m=\u001b[39m search3\u001b[39m.\u001b[39mpredict(X_test_var)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:499\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \n\u001b[1;32m    483\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    498\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:798\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns are missing: \u001b[39m\u001b[39m{\u001b[39;00mdiff\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    795\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    800\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(\n\u001b[1;32m    801\u001b[0m     X,\n\u001b[1;32m    802\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m     column_as_strings\u001b[39m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    807\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 19 features, but ColumnTransformer is expecting 80 features as input."
     ]
    }
   ],
   "source": [
    "y_test_pred_tree = search.predict(X_test_var)\n",
    "y_test_pred_knn = search2.predict(X_test_var)\n",
    "y_test_pred_rf = search3.predict(X_test_var)\n",
    "y_test_pred_SGDR = sgd_pipeline.predict(X_test_var)\n",
    "y_test_pred_lr = lr_pipeline.predict(X_test_var)\n",
    "\n",
    "\n",
    "baseline_tree_r2 = r2_score(y_test, y_test_pred_tree)\n",
    "baseline_knn_r2 = r2_score(y_test, y_test_pred_knn)\n",
    "baseline_rf = r2_score(y_test, y_test_pred_rf)\n",
    "baseline_SGDR = r2_score(y_test, y_test_pred_SGDR)\n",
    "baseline_lr = r2_score(y_test, y_test_pred_lr)\n",
    "\n",
    "\n",
    "performances.loc[\"varThreshold_0_02\", 'decision_tree'] = round(baseline_tree_r2,3)\n",
    "performances.loc[\"varThreshold_0_02\", 'knn'] = round(baseline_knn_r2,3) \n",
    "performances.loc[\"varThreshold_0_02\", 'RF'] = round(baseline_rf,3)\n",
    "performances.loc[\"varThreshold_0_02\", 'SGDR'] = round(baseline_SGDR, 2)\n",
    "performances.loc[\"varThreshold_0_02\", 'LR'] = round(baseline_lr,3)\n",
    "\n",
    "\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_sumbmition \u001b[39m=\u001b[39m housing_data[\u001b[39m0\u001b[39m:\u001b[39m1459\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ids_com[\u001b[39m'\u001b[39m\u001b[39mExpensive\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m search4\u001b[39m.\u001b[39mpredict(X_sumbmition) \u001b[39m# only cange the piplene! \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Smirnov/Documents/GitHub/supervised_learning_project/12_housing_data_regression-features.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ids_com\u001b[39m.\u001b[39mto_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39msubmission_9.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search4' is not defined"
     ]
    }
   ],
   "source": [
    "X_sumbmition = housing_data[0:1459]\n",
    "ids_com['Expensive'] = search4.predict(X_sumbmition) # only cange the piplene! \n",
    "ids_com.to_csv(r'submission_9.csv', index=False) #only cahnge ist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
